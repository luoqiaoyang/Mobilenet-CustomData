{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T13:55:31.933784Z",
     "start_time": "2017-12-24T13:55:31.409767Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T13:19:04.236011Z",
     "start_time": "2017-12-24T13:19:04.229399Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T13:34:29.155355Z",
     "start_time": "2017-12-24T13:34:28.343413Z"
    }
   },
   "outputs": [],
   "source": [
    "root_path = '/home/yang/dataset/imagenet/fruits/train/'\n",
    "im_list = [os.path.join(root_path, 'apple', i) for i in os.listdir(root_path + 'apple')[:4]]\n",
    "im_list += [os.path.join(root_path, 'avocado', i) for i in os.listdir(root_path + 'avocado')[:4]]\n",
    "im_list += [os.path.join(root_path, 'banana', i) for i in os.listdir(root_path + 'banana')[:4]]\n",
    "im_list += [os.path.join(root_path, 'kiwi', i) for i in os.listdir(root_path + 'kiwi')[:4]]\n",
    "im_list += [os.path.join(root_path, 'watermelon', i) for i in os.listdir(root_path + 'watermelon')[:5]]\n",
    "\n",
    "nrows = 3\n",
    "ncols = 3\n",
    "figsize = (8, 8)\n",
    "_, figs = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        figs[i][j].imshow(Image.open(im_list[nrows*i+j]))\n",
    "        figs[i][j].axes.get_xaxis().set_visible(False)\n",
    "        figs[i][j].axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T13:55:34.323189Z",
     "start_time": "2017-12-24T13:55:34.303520Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tf = tfs.Compose([\n",
    "    tfs.RandomResizedCrop(224),\n",
    "    tfs.RandomHorizontalFlip(),\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "valid_tf = tfs.Compose([\n",
    "    #tfs.Resize(256),\n",
    "    tfs.CenterCrop(224),\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_tf_random = tfs.Compose([\n",
    "    #tfs.Resize(256),\n",
    "    tfs.RandomResizedCrop(224),\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_tf_resize = tfs.Compose([\n",
    "    tfs.Resize(256),\n",
    "    tfs.RandomResizedCrop(224),\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T13:55:34.923925Z",
     "start_time": "2017-12-24T13:55:34.904136Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = ImageFolder('/home/yang/dataset/imagenet/fruits/train/', train_tf)\n",
    "valid_set = ImageFolder('/home/yang/dataset/imagenet/fruits/val100/', valid_tf)\n",
    "valid_set_random = ImageFolder('/home/yang/dataset/imagenet/fruits/val100/', valid_tf_random)\n",
    "valid_set_resize = ImageFolder('/home/yang/dataset/imagenet/fruits/val100/', valid_tf_resize)\n",
    "\n",
    "train_data = DataLoader(train_set, 64, True, num_workers=4)\n",
    "valid_data = DataLoader(valid_set, 8, False, num_workers=2)\n",
    "#valid_data_random = DataLoader(valid_set_random, 8, False, num_workers=2)\n",
    "#valid_data_resize = DataLoader(valid_set_resize, 8, False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNet, self).__init__()\n",
    "\n",
    "        # Normal convolution block followed by Batchnorm (CONV_3x3-->BN-->Relu)\n",
    "        def conv_bn(inp, oup, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # Depthwise convolution block (CONV_BLK_3x3-->BN-->Relu-->CONV_1x1-->BN-->Relu)\n",
    "        def conv_dw(inp, oup, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "                nn.BatchNorm2d(inp),\n",
    "                nn.ReLU(inplace=True),\n",
    "    \n",
    "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            conv_bn(  3,  32, 2), \n",
    "            conv_dw( 32,  64, 1),\n",
    "            conv_dw( 64, 128, 2),\n",
    "            conv_dw(128, 128, 1),\n",
    "            conv_dw(128, 256, 2),\n",
    "            conv_dw(256, 256, 1),\n",
    "            conv_dw(256, 512, 2),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 512, 1),\n",
    "            conv_dw(512, 1024, 2),\n",
    "            conv_dw(1024, 1024, 1),\n",
    "            nn.AvgPool2d(7),\n",
    "        )\n",
    "        self.fc = nn.Linear(1024, 1000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet()\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model).cuda()\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.load('moblienet_30e.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - load directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - remove prefix in paramas\n",
    "\n",
    "**Save model state_dict into a variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Filter out unnecessary keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = {k: v for k, v in params.items() if k in model_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Overwrite entries in the existing state dict **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict.update(pretrained_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Load the new state dict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:01:20.500482Z",
     "start_time": "2017-12-24T14:01:20.497623Z"
    }
   },
   "outputs": [],
   "source": [
    "# the new defined layer have requires_grad=True by default.\n",
    "model.fc = nn.Linear(2048, 5)\n",
    "#model.fc.parameters.requires_grad\n",
    "#model.fc = nn.Linear(2048, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:01:21.918643Z",
     "start_time": "2017-12-24T14:01:21.910416Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Sef different learning rates in different layers\n",
    "optimizer = torch.optim.SGD([{'params':model.module.model.parameters(),'lr':1e-2},\n",
    "                             {'params':model.module.fc.parameters(), 'lr':1e-3}], weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:02:38.033419Z",
     "start_time": "2017-12-24T14:01:22.868897Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import train\n",
    "from utils import validate\n",
    "from utils import validate_random\n",
    "from utils import validate_resize\n",
    "\n",
    "epochs = 15\n",
    "for e in range(epochs):\n",
    "    train(model, train_data, e, optimizer, criterion)\n",
    "    validate(model, valid_data, e, optimizer, criterion)\n",
    "    #validate_random(model, valid_data_random, e, optimizer, criterion)\n",
    "    #validate_resize(model, valid_data_resize, e, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mobienet_30e.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load save model\n",
    "\n",
    "When we saved our pretrained model, we could load it without trainning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model = MobileNet()\n",
    "\n",
    "# transform the model to DataParallel\n",
    "mobilenet_model = torch.nn.DataParallel(mobilenet_model).cuda()\n",
    "\n",
    "# load params into a variable\n",
    "params = torch.load('mobienet_30e.pth.tar')['state_dict']\n",
    "\n",
    "# load params to model\n",
    "mobilenet_model.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:03:14.457363Z",
     "start_time": "2017-12-24T14:03:14.448500Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:03:20.939986Z",
     "start_time": "2017-12-24T14:03:20.719813Z"
    }
   },
   "outputs": [],
   "source": [
    "im1 = Image.open('/home/yang/dataset/imagenet/fruits/val/kiwi/756419172.jpg')\n",
    "im1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-24T14:04:53.590993Z",
     "start_time": "2017-12-24T14:04:53.533560Z"
    }
   },
   "outputs": [],
   "source": [
    "im = valid_tf(im1)\n",
    "out = model(Variable(im.unsqueeze(0),volatile=True).cuda())\n",
    "pred_label = out.max(1)[1].data[0]\n",
    "print('predict label: {}'.format(train_set.classes[pred_label]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
